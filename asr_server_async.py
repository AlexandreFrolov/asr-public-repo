import asyncio
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
import uvicorn
from faster_whisper import WhisperModel
import numpy as np
import torch
import wave
import os
import time
from datetime import datetime
import sys

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
SAMPLE_RATE = 16000
BUFFER_SECONDS = 3

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
DEBUG = os.environ.get("DEBUG", "false").lower() == "true"

# –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
if len(sys.argv) > 1 and "--debug" in sys.argv:
    DEBUG = True

AUDIO_SAVE_DIR = "recordings" if DEBUG else None  # –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏

app = FastAPI()

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏
if DEBUG and AUDIO_SAVE_DIR and not os.path.exists(AUDIO_SAVE_DIR):
    os.makedirs(AUDIO_SAVE_DIR)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üöÄ Starting speech recognition server")
print(f"üì° Using device: {device}")
print(f"üîß Buffer size: {BUFFER_SECONDS} seconds")
print(f"‚ö° Model: large-v3")
print(f"üêõ Debug mode: {'ENABLED' if DEBUG else 'DISABLED'}")
if DEBUG:
    print(f"üìÅ Audio recordings will be saved to: {AUDIO_SAVE_DIR}")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper
model = WhisperModel("large-v3", device=device)

async def transcribe_audio(audio_float: np.ndarray):
    """–ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
    return await asyncio.to_thread(model.transcribe, audio_float, beam_size=5, language="ru")

def save_audio_to_wav(audio_int16: np.ndarray, filename: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –≤ WAV —Ñ–∞–π–ª (—Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏)"""
    try:
        with wave.open(filename, 'wb') as wav_file:
            wav_file.setnchannels(1)  # –º–æ–Ω–æ
            wav_file.setsampwidth(2)   # 16 –±–∏—Ç = 2 –±–∞–π—Ç–∞
            wav_file.setframerate(SAMPLE_RATE)
            wav_file.writeframes(audio_int16.tobytes())
        print(f"üíæ Audio saved to {filename}")
        return True
    except Exception as e:
        print(f"‚ö† Error saving WAV file: {e}")
        return False

@app.websocket("/ws/asr")
async def asr_ws(ws: WebSocket):
    await ws.accept()
    print("‚úÖ Client connected")

    buffer = np.zeros(0, dtype=np.int16)
    all_audio = np.zeros(0, dtype=np.int16) if DEBUG else None  # –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ–≥–æ –∞—É–¥–∏–æ —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏
    
    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏
    if DEBUG:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        connection_id = id(ws)
        wav_filename = os.path.join(AUDIO_SAVE_DIR, f"audio_{timestamp}_{connection_id}.wav")

    try:
        while True:
            try:
                data = await ws.receive_bytes()
            except WebSocketDisconnect:
                print("‚ùå Client disconnected")
                break
            except Exception as e:
                print("‚ö† Error receiving data:", e)
                continue

            pcm = np.frombuffer(data, dtype=np.int16)
            buffer = np.concatenate([buffer, pcm])
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏
            if DEBUG and all_audio is not None:
                all_audio = np.concatenate([all_audio, pcm])
            
            # –í—ã–≤–æ–¥ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏
            if DEBUG:
                print(f"üì• Received chunk: {len(pcm)} samples, buffer total: {len(buffer)} samples")
                print(f"üìä Chunk stats - Min: {np.min(pcm)}, Max: {np.max(pcm)}, Mean: {np.mean(np.abs(pcm)):.1f}")

            # –ï—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–∏ ‚â• BUFFER_SECONDS, –¥–µ–ª–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            if len(buffer) >= SAMPLE_RATE * BUFFER_SECONDS:
                audio_float = buffer.astype(np.float32) / 32768.0
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∞–º–ø–ª–∏—Ç—É–¥—ã —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏
                if DEBUG:
                    max_amplitude = np.max(np.abs(audio_float))
                    print(f"üìà Buffer amplitude: {max_amplitude:.4f} (target: 0.1-0.9)")
                
                try:
                    segments, info = await transcribe_audio(audio_float)
                    for segment in segments:
                        await ws.send_text(segment.text)
                        # –í—ã–≤–æ–¥–∏–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤—Å–µ–≥–¥–∞
                        if DEBUG:
                            # –í —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                            segment_info = f"üìù Segment: {segment.start:.2f}s -> {segment.end:.2f}s"
                            if hasattr(segment, 'avg_logprob'):
                                segment_info += f" | Logprob: {segment.avg_logprob:.2f}"
                            if hasattr(segment, 'no_speech_prob'):
                                segment_info += f" | No speech prob: {segment.no_speech_prob:.2f}"
                            segment_info += f" | Text: '{segment.text}'"
                            print(segment_info)
                        else:
                            # –í –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
                            print(f"üìù '{segment.text}'")
                    
                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏
                    if DEBUG and hasattr(info, 'language'):
                        print(f"üåê Detected language: {info.language} (probability: {info.language_probability:.2f})")
                        
                except Exception as e:
                    print("‚ö† Transcription error:", e)

                buffer = np.zeros(0, dtype=np.int16)

    except Exception as e:
        print("‚ùå Unexpected error:", e)
    finally:
        print("‚èπ Connection closed")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –ø–æ–ª—É—á–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ –≤ WAV —Ñ–∞–π–ª —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏
        if DEBUG and all_audio is not None and len(all_audio) > 0:
            print(f"üíø Total audio received: {len(all_audio)} samples ({len(all_audio)/SAMPLE_RATE:.2f} seconds)")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–∏–≥–Ω–∞–ª–∞
            max_val = np.max(np.abs(all_audio))
            avg_val = np.mean(np.abs(all_audio))
            print(f"üìä Signal stats - Max: {max_val}, Avg: {avg_val:.1f}")
            
            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
            if max_val < 1000:
                print("‚ö† WARNING: Signal too weak! Check microphone gain.")
            elif max_val > 30000:
                print("‚ö† WARNING: Possible clipping (signal too strong)!")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ WAV
            success = save_audio_to_wav(all_audio, wav_filename)
            if success:
                print(f"üéµ File saved: {wav_filename}")
        
        try:
            await ws.close()
        except Exception:
            pass

@app.get("/recordings")
async def list_recordings():
    """API endpoint –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π (—Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏)"""
    if not DEBUG or not os.path.exists(AUDIO_SAVE_DIR):
        return {"recordings": [], "message": "Debug mode is disabled"}
    
    files = []
    for filename in os.listdir(AUDIO_SAVE_DIR):
        if filename.endswith('.wav'):
            filepath = os.path.join(AUDIO_SAVE_DIR, filename)
            size = os.path.getsize(filepath)
            files.append({
                "name": filename,
                "size_bytes": size,
                "size_mb": size / (1024 * 1024),
                "path": filepath
            })
    
    return {"recordings": files}

@app.delete("/recordings/clear")
async def clear_recordings():
    """–û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏ (—Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏)"""
    if not DEBUG:
        return {"cleared": 0, "message": "Debug mode is disabled"}
    
    if os.path.exists(AUDIO_SAVE_DIR):
        count = 0
        for filename in os.listdir(AUDIO_SAVE_DIR):
            if filename.endswith('.wav'):
                os.remove(os.path.join(AUDIO_SAVE_DIR, filename))
                count += 1
        return {"cleared": count, "message": f"Removed {count} recording files"}
    return {"cleared": 0, "message": "No recordings to clear"}

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–∞"""
    return {
        "status": "ok",
        "device": device,
        "model": "large-v3",
        "debug_mode": DEBUG,
        "buffer_seconds": BUFFER_SECONDS
    }

if __name__ == "__main__":
    print("-" * 50)
    print(f"üìù Usage: DEBUG=true python3 {sys.argv[0]} [--debug]")
    print(f"üìù –∏–ª–∏: python3 {sys.argv[0]} --debug")
    print("-" * 50)
    
    uvicorn.run(
        "asr_server_async:app",
        host="0.0.0.0",
        port=8000,
        log_level="info",
        access_log=False  # –í—ã–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏ –¥–æ—Å—Ç—É–ø–∞ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    )
